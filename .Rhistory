# could keep the page submit buttons to see how long someone thought about something
df <- df %>%
# reformat variable names
clean_names() %>%
rename('startDate'='v8', 'endDate'='v9', 'finished'='v10', 'consent'='q44', 'att_check2'='lp_scale_2_6', 'includeOrExclude'='q50') %>%
# Remove survey metadata, blank surveys, and survey with improper responses
select(-(v2:v7), -q1, -(q45_1:q2), -(disc_time_1:disc_time_4), -(learn_time_1:learn_time_4), -(perf_time_1:perf_time_4), -(q18_1:q18_4), -(q21_1:q21_4), -(note_time_1:note_time_4),
-(dg_time_1:dg_time_4), -(q31_1:q31_4), -(q34_1:q34_4), -q24, -q46) %>% # remove metadata columns
filter(consent == 1) %>%  # remove people who decided not to participate , also removes the extra header
filter(startDate != "5/22/13 10:06", startDate!= "5/23/13 22:29") %>%   # remove bad survey response (gave the same response to every question, except for the free response where they responded with "f")
# REMOVE SURVEYS WHERE PEOPLE DIDN'T ANSWER THE FIRST QUESTION
# unencoding some responses and converting to factor so they are easier to use
mutate(gender = case_when(gender == "1" ~ "male", gender == 2 ~ "female")) %>% # explicitly code gender
mutate(gender = factor(gender)) %>% # then convert to factor to make it easier to work with in model
mutate(includeOrExclude = case_when(includeOrExclude == "1" ~ "exclude", includeOrExclude == "2" ~ "include")) %>%# explicitly code include or exclude
mutate(includeOrExclude = factor(includeOrExclude)) %>% # convert to factor
# create columns indicating participant's condition
mutate(priming_received = case_when(q10 == "1" ~ "learning", q13 == "1" ~ "performance")) %>% # create column indicating priming received
select(-q10, -q13) %>% # remove separate columns that used to indicate which priming was received
mutate(inOrOut = case_when(q17 == "1" ~ "in", q20 == "1" ~ "out", q38 == "1" ~ "in", q41 == "1" ~ "out")) %>% # indicate in or out-group condition
select(-(q16:q42_4)) %>%  # remove the separate columns used to indicate in or out-group
# singular column indicating participants condition
mutate(condition = case_when(priming_received == "learning" & inOrOut == "in" ~ "learn_in",
priming_received == "learning" & inOrOut == "out" ~ "learn_out",
priming_received == "performance" & inOrOut == "in" ~ "perf_in",
priming_received == "performance" & inOrOut == "out" ~ "learn_out")) %>%
# combine priming responses into one column
mutate(priming_response = case_when(priming_received == "learning" ~ learn, priming_received == "performance" ~ perform)) %>%
# indicate if someone passed the second attention check with a 1 and 0 otherwise
mutate(att_check2 = ifelse(att_check2 == "6", 1, 0)) %>%
# clean dictator game free response
mutate(dg = as.numeric(gsub("\\D", "", dg))) %>% # remove extra text, just have numbers
mutate(dg = case_when(dg == 125 ~ 25, .default = dg)) %>%  # remove typo, was likely supposed to be 25 since that's the max possible value
# convert data types as needed
mutate_at(c("pt_1", "pt_2", "pt_3", "pt_4", "pt_5"), as.numeric) %>% # convert to numeric to calculate the mean
mutate_at(c("lp_scale_1_3", "lp_scale_1_4", "lp_scale_1_5", "lp_scale_1_8", "lp_scale_1_9", "lp_scale_2_2", "lp_scale_2_5", "lp_scale_2_8",
"lp_scale_1_1", "lp_scale_1_2", "lp_scale_1_6", "lp_scale_1_7", "lp_scale_2_1", "lp_scale_2_3", "lp_scale_2_4", "lp_scale_2_7"),
as.numeric) %>%
# calculate average scores on scales with multiple items
# have to reverse code some items first
# reverse coding for perspective taking
mutate(pt_1_reversed = case_when(pt_1 == "7" ~ 1, pt_1 == "6" ~ 2, pt_1 == "5" ~ 3, pt_1 == "4" ~ 4, pt_1 == "3" ~ 5, pt_1 == "2" ~ 6, pt_1 == "1" ~ 7),
pt_3_reversed = case_when(pt_3 == "7" ~ 1, pt_3 == "6" ~ 2, pt_3 == "5" ~ 3, pt_3 == "4" ~ 4, pt_3 == "3" ~ 5, pt_3 == "2" ~ 6, pt_3 == "1" ~ 7),
pt_5_reversed = case_when(pt_5 == "7" ~ 1, pt_5 == "6" ~ 2, pt_5 == "5" ~ 3, pt_5 == "4" ~ 4, pt_5 == "3" ~ 5, pt_5 == "2" ~ 6, pt_5 == "1" ~ 7)) %>%
# avg for PT
mutate(PT_avg = rowMeans(select(., c("pt_1_reversed", "pt_2", "pt_3_reversed", "pt_4", "pt_5_reversed")), na.rm=T)) %>%
# avg for trait-level learning orientation
# note: someone will still have an average if they're missing an answer, but the NA won't be included in the denominator
mutate(trait_learning_avg = rowMeans(select(., c("lp_scale_1_3", "lp_scale_1_4", "lp_scale_1_5", "lp_scale_1_8", "lp_scale_1_9", "lp_scale_2_2", "lp_scale_2_5", "lp_scale_2_8")), na.rm=T)) %>%
# avg for trait-level learning orientation
# same note as above
mutate(trait_performance_avg = rowMeans(select(., c("lp_scale_1_1", "lp_scale_1_2", "lp_scale_1_6", "lp_scale_1_7", "lp_scale_2_1", "lp_scale_2_3", "lp_scale_2_4", "lp_scale_2_7")), na.rm=T)) %>%
# reorder columns
select(startDate:self_disc, priming_response, att_check:condition, pt_1_reversed:trait_performance_avg)
# clean letter of support text and extract sentiment
# preview the cleaned dataset
glimpse(df)
# report amount of data
num_columns <- ncol(df)
num_rows <- nrow(df)
# determine missing data for each participant
df$na_counts <- rowSums(is.na(df))
# output number of participants with significant missing data
num_participants_removed <- sum(df$na_counts >= 32)
# remove participants with substantial amounts of missing data
removed_participants <- df %>% filter(na_counts >= 32)
df <- df %>% filter(na_counts < 32)
max_missing <- max(df$na_counts) # report the maximum number of missing responses now
df <- df %>% select(-na_counts, -finished, -consent) # no longer need na counts.
# Also don't need the finished or consent columns. Anyone who took the survey consented, and finished doesn't seem to actually indicate if someone finished the survey
remaining_participants <- nrow(df) # report the remaining participants
# save the cleaned dataset
write.csv(df, 'LP_dictator_cleaned.csv', row.names=F)
ggplot(removed_participants, aes(x=age)) + geom_bar() +
scale_y_continuous(breaks = seq(0,9,1)) +
ggtitle('Age of participants') +
theme(plot.title = element_text(hjust = 0.5))
print('Summary statistics for the age of removed participants:')
summary(as.numeric(removed_participants$age))
print("For comparisons' sake, here are the summary statistics for the age of the included participants:")
summary(as.numeric(df$age))
print('Gender of removed participants:')
table(removed_participants$gender)
print('Gender of remaining participants:')
table(df$gender)
# learning vs performance
knitr::kable(table(df$priming_received))
# in or out
knitr::kable(table(df$inOrOut))
# condition
knitr::kable(table(df$inOrOut, df$priming_received))
# gender tables
knitr::kable(table(df$gender))
knitr::kable(table(df$gender, df$priming_received))
knitr::kable(table(df$gender, df$inOrOut))
print('How many people answered the first attention check, which asked them to summarize what they read?')
knitr::kable(table(!is.na(df$att_check)))
table(df$att_check2)
print('How many people said to include or exclude their responses?')
table(df$includeOrExclude)
df <- read.csv('LP_Dictator.csv', na.strings=c("", " "))
# could keep the page submit buttons to see how long someone thought about something
df <- df %>%
# reformat variable names
clean_names() %>%
rename('startDate'='v8', 'endDate'='v9', 'finished'='v10', 'consent'='q44', 'att_check2'='lp_scale_2_6', 'includeOrExclude'='q50') %>%
# Remove survey metadata, blank surveys, and survey with improper responses
select(-(v2:v7), -q1, -(q45_1:q2), -(disc_time_1:disc_time_4), -(learn_time_1:learn_time_4), -(perf_time_1:perf_time_4), -(q18_1:q18_4), -(q21_1:q21_4), -(note_time_1:note_time_4),
-(dg_time_1:dg_time_4), -(q31_1:q31_4), -(q34_1:q34_4), -q24, -q46) %>% # remove metadata columns
filter(consent == 1) %>%  # remove people who decided not to participate , also removes the extra header
filter(startDate != "5/22/13 10:06", startDate!= "5/23/13 22:29") %>%   # remove bad survey response (gave the same response to every question, except for the free response where they responded with "f")
# REMOVE SURVEYS WHERE PEOPLE DIDN'T ANSWER THE FIRST QUESTION
# unencoding some responses and converting to factor so they are easier to use
mutate(gender = case_when(gender == "1" ~ "male", gender == 2 ~ "female")) %>% # explicitly code gender
mutate(gender = factor(gender)) %>% # then convert to factor to make it easier to work with in model
mutate(includeOrExclude = case_when(includeOrExclude == "1" ~ "exclude", includeOrExclude == "2" ~ "include")) %>%# explicitly code include or exclude
mutate(includeOrExclude = factor(includeOrExclude)) %>% # convert to factor
# create columns indicating participant's condition
mutate(priming_received = case_when(q10 == "1" ~ "learning", q13 == "1" ~ "performance")) %>% # create column indicating priming received
select(-q10, -q13) %>% # remove separate columns that used to indicate which priming was received
mutate(inOrOut = case_when(q17 == "1" ~ "in", q20 == "1" ~ "out", q38 == "1" ~ "in", q41 == "1" ~ "out")) %>% # indicate in or out-group condition
select(-(q16:q42_4)) %>%  # remove the separate columns used to indicate in or out-group
# singular column indicating participants condition
mutate(condition = case_when(priming_received == "learning" & inOrOut == "in" ~ "learn_in",
priming_received == "learning" & inOrOut == "out" ~ "learn_out",
priming_received == "performance" & inOrOut == "in" ~ "perf_in",
priming_received == "performance" & inOrOut == "out" ~ "learn_out")) %>%
# combine priming responses into one column
mutate(priming_response = case_when(priming_received == "learning" ~ learn, priming_received == "performance" ~ perform)) %>%
# indicate if someone passed the second attention check with a 1 and 0 otherwise
mutate(att_check2 = ifelse(att_check2 == "6", 1, 0)) %>%
# clean dictator game free response
mutate(dg = as.numeric(gsub("\\D", "", dg))) %>% # remove extra text, just have numbers
mutate(dg = case_when(dg == 125 ~ 25, .default = dg)) %>%  # remove typo, was likely supposed to be 25 since that's the max possible value
# convert data types as needed
mutate_at(c("pt_1", "pt_2", "pt_3", "pt_4", "pt_5"), as.numeric) %>% # convert to numeric to calculate the mean
mutate_at(c("lp_scale_1_3", "lp_scale_1_4", "lp_scale_1_5", "lp_scale_1_8", "lp_scale_1_9", "lp_scale_2_2", "lp_scale_2_5", "lp_scale_2_8",
"lp_scale_1_1", "lp_scale_1_2", "lp_scale_1_6", "lp_scale_1_7", "lp_scale_2_1", "lp_scale_2_3", "lp_scale_2_4", "lp_scale_2_7"),
as.numeric) %>%
# calculate average scores on scales with multiple items
# have to reverse code some items first
# reverse coding for perspective taking
mutate(pt_1_reversed = case_when(pt_1 == "7" ~ 1, pt_1 == "6" ~ 2, pt_1 == "5" ~ 3, pt_1 == "4" ~ 4, pt_1 == "3" ~ 5, pt_1 == "2" ~ 6, pt_1 == "1" ~ 7),
pt_3_reversed = case_when(pt_3 == "7" ~ 1, pt_3 == "6" ~ 2, pt_3 == "5" ~ 3, pt_3 == "4" ~ 4, pt_3 == "3" ~ 5, pt_3 == "2" ~ 6, pt_3 == "1" ~ 7),
pt_5_reversed = case_when(pt_5 == "7" ~ 1, pt_5 == "6" ~ 2, pt_5 == "5" ~ 3, pt_5 == "4" ~ 4, pt_5 == "3" ~ 5, pt_5 == "2" ~ 6, pt_5 == "1" ~ 7)) %>%
# avg for PT
mutate(PT_avg = rowMeans(select(., c("pt_1_reversed", "pt_2", "pt_3_reversed", "pt_4", "pt_5_reversed")), na.rm=T)) %>%
# avg for trait-level learning orientation
# note: someone will still have an average if they're missing an answer, but the NA won't be included in the denominator
mutate(trait_learning_avg = rowMeans(select(., c("lp_scale_1_3", "lp_scale_1_4", "lp_scale_1_5", "lp_scale_1_8", "lp_scale_1_9", "lp_scale_2_2", "lp_scale_2_5", "lp_scale_2_8")), na.rm=T)) %>%
# avg for trait-level learning orientation
# same note as above
mutate(trait_performance_avg = rowMeans(select(., c("lp_scale_1_1", "lp_scale_1_2", "lp_scale_1_6", "lp_scale_1_7", "lp_scale_2_1", "lp_scale_2_3", "lp_scale_2_4", "lp_scale_2_7")), na.rm=T)) %>%
# reorder columns
select(startDate:self_disc, priming_response, att_check:condition, pt_1_reversed:trait_performance_avg)
# clean letter of support text and extract sentiment
# preview the cleaned dataset
glimpse(df)
knitr::opts_chunk$set(echo = F)
library(tidyverse)
# install.packages("janitor")
library(janitor) # used to clean the column names
df <- read.csv('LP_Dictator.csv', na.strings=c("", " "))
# could keep the page submit buttons to see how long someone thought about something
df <- df %>%
# reformat variable names
clean_names() %>%
rename('startDate'='v8', 'endDate'='v9', 'finished'='v10', 'consent'='q44', 'att_check2'='lp_scale_2_6', 'includeOrExclude'='q50') %>%
# Remove survey metadata, blank surveys, and survey with improper responses
select(-(v2:v7), -q1, -(q45_1:q2), -(disc_time_1:disc_time_4), -(learn_time_1:learn_time_4), -(perf_time_1:perf_time_4), -(q18_1:q18_4), -(q21_1:q21_4), -(note_time_1:note_time_4),
-(dg_time_1:dg_time_4), -(q31_1:q31_4), -(q34_1:q34_4), -q24, -q46) %>% # remove metadata columns
filter(consent == 1) %>%  # remove people who decided not to participate , also removes the extra header
filter(startDate != "5/22/13 10:06", startDate!= "5/23/13 22:29") %>%   # remove bad survey response (gave the same response to every question, except for the free response where they responded with "f")
# REMOVE SURVEYS WHERE PEOPLE DIDN'T ANSWER THE FIRST QUESTION
# unencoding some responses and converting to factor so they are easier to use
mutate(gender = case_when(gender == "1" ~ "male", gender == 2 ~ "female")) %>% # explicitly code gender
mutate(gender = factor(gender)) %>% # then convert to factor to make it easier to work with in model
mutate(includeOrExclude = case_when(includeOrExclude == "1" ~ "exclude", includeOrExclude == "2" ~ "include")) %>%# explicitly code include or exclude
mutate(includeOrExclude = factor(includeOrExclude)) %>% # convert to factor
# create columns indicating participant's condition
mutate(priming_received = case_when(q10 == "1" ~ "learning", q13 == "1" ~ "performance")) %>% # create column indicating priming received
select(-q10, -q13) %>% # remove separate columns that used to indicate which priming was received
mutate(inOrOut = case_when(q17 == "1" ~ "in", q20 == "1" ~ "out", q38 == "1" ~ "in", q41 == "1" ~ "out")) %>% # indicate in or out-group condition
select(-(q16:q42_4)) %>%  # remove the separate columns used to indicate in or out-group
# singular column indicating participants condition
mutate(condition = case_when(priming_received == "learning" & inOrOut == "in" ~ "learn_in",
priming_received == "learning" & inOrOut == "out" ~ "learn_out",
priming_received == "performance" & inOrOut == "in" ~ "perf_in",
priming_received == "performance" & inOrOut == "out" ~ "learn_out")) %>%
# combine priming responses into one column
mutate(priming_response = case_when(priming_received == "learning" ~ learn, priming_received == "performance" ~ perform)) %>%
# indicate if someone passed the second attention check with a 1 and 0 otherwise
mutate(att_check2 = ifelse(att_check2 == "6", 1, 0)) %>%
# clean dictator game free response
mutate(dg = as.numeric(gsub("\\D", "", dg))) %>% # remove extra text, just have numbers
mutate(dg = case_when(dg == 125 ~ 25, .default = dg)) %>%  # remove typo, was likely supposed to be 25 since that's the max possible value
# convert data types as needed
mutate_at(c("pt_1", "pt_2", "pt_3", "pt_4", "pt_5"), as.numeric) %>% # convert to numeric to calculate the mean
mutate_at(c("lp_scale_1_3", "lp_scale_1_4", "lp_scale_1_5", "lp_scale_1_8", "lp_scale_1_9", "lp_scale_2_2", "lp_scale_2_5", "lp_scale_2_8",
"lp_scale_1_1", "lp_scale_1_2", "lp_scale_1_6", "lp_scale_1_7", "lp_scale_2_1", "lp_scale_2_3", "lp_scale_2_4", "lp_scale_2_7"),
as.numeric) %>%
# calculate average scores on scales with multiple items
# have to reverse code some items first
# reverse coding for perspective taking
mutate(pt_1_reversed = case_when(pt_1 == "7" ~ 1, pt_1 == "6" ~ 2, pt_1 == "5" ~ 3, pt_1 == "4" ~ 4, pt_1 == "3" ~ 5, pt_1 == "2" ~ 6, pt_1 == "1" ~ 7),
pt_3_reversed = case_when(pt_3 == "7" ~ 1, pt_3 == "6" ~ 2, pt_3 == "5" ~ 3, pt_3 == "4" ~ 4, pt_3 == "3" ~ 5, pt_3 == "2" ~ 6, pt_3 == "1" ~ 7),
pt_5_reversed = case_when(pt_5 == "7" ~ 1, pt_5 == "6" ~ 2, pt_5 == "5" ~ 3, pt_5 == "4" ~ 4, pt_5 == "3" ~ 5, pt_5 == "2" ~ 6, pt_5 == "1" ~ 7)) %>%
# avg for PT
mutate(PT_avg = rowMeans(select(., c("pt_1_reversed", "pt_2", "pt_3_reversed", "pt_4", "pt_5_reversed")), na.rm=T)) %>%
# avg for trait-level learning orientation
# note: someone will still have an average if they're missing an answer, but the NA won't be included in the denominator
mutate(trait_learning_avg = rowMeans(select(., c("lp_scale_1_3", "lp_scale_1_4", "lp_scale_1_5", "lp_scale_1_8", "lp_scale_1_9", "lp_scale_2_2", "lp_scale_2_5", "lp_scale_2_8")), na.rm=T)) %>%
# avg for trait-level learning orientation
# same note as above
mutate(trait_performance_avg = rowMeans(select(., c("lp_scale_1_1", "lp_scale_1_2", "lp_scale_1_6", "lp_scale_1_7", "lp_scale_2_1", "lp_scale_2_3", "lp_scale_2_4", "lp_scale_2_7")), na.rm=T)) %>%
# reorder columns
select(startDate:self_disc, priming_response, att_check:condition, pt_1_reversed:trait_performance_avg)
# clean letter of support text and extract sentiment
# preview the cleaned dataset
glimpse(df)
# report amount of data
num_columns <- ncol(df)
num_rows <- nrow(df)
# determine missing data for each participant
df$na_counts <- rowSums(is.na(df))
# output number of participants with significant missing data
num_participants_removed <- sum(df$na_counts >= 32)
# remove participants with substantial amounts of missing data
removed_participants <- df %>% filter(na_counts >= 32)
df <- df %>% filter(na_counts < 32)
max_missing <- max(df$na_counts) # report the maximum number of missing responses now
df <- df %>% select(-na_counts, -finished, -consent) # no longer need na counts.
# Also don't need the finished or consent columns. Anyone who took the survey consented, and finished doesn't seem to actually indicate if someone finished the survey
remaining_participants <- nrow(df) # report the remaining participants
# save the cleaned dataset
write.csv(df, 'LP_dictator_cleaned.csv', row.names=F)
ggplot(removed_participants, aes(x=age)) + geom_bar() +
scale_y_continuous(breaks = seq(0,9,1)) +
ggtitle('Age of participants') +
theme(plot.title = element_text(hjust = 0.5))
print('Summary statistics for the age of removed participants:')
summary(as.numeric(removed_participants$age))
print("For comparisons' sake, here are the summary statistics for the age of the included participants:")
summary(as.numeric(df$age))
print('Gender of removed participants:')
table(removed_participants$gender)
print('Gender of remaining participants:')
table(df$gender)
# learning vs performance
knitr::kable(table(df$priming_received))
# in or out
knitr::kable(table(df$inOrOut))
# condition
knitr::kable(table(df$inOrOut, df$priming_received))
# gender tables
knitr::kable(table(df$gender))
knitr::kable(table(df$gender, df$priming_received))
knitr::kable(table(df$gender, df$inOrOut))
print('How many people answered the first attention check, which asked them to summarize what they read?')
knitr::kable(table(!is.na(df$att_check)))
knitr::kable(table(df$att_check2))
print('How many people said to include or exclude their responses?')
table(df$includeOrExclude)
iris = load_iris()
library(tidyverse)
library(ggfortify)
colorize <- function(x, color = 2) {
cols <- palette.colors()
color <- cols[color + 1]
if (knitr::is_latex_output()) {
sprintf("\\textcolor{%s}{%s}", color, x)
} else if (knitr::is_html_output()) {
sprintf("<span style='color: %s;'>%s</span>", color,
x)
} else x
}
f <- str_c("https://raw.githubusercontent.com/theodds/",
"SDS-383D/main/Challenger.csv")
challenger      <- read.csv(f)
challenger      <- drop_na(challenger)
challenger$Fail <- ifelse(challenger$Fail == "yes", 1, 0)
knitr::kable(head(challenger))
# fit the model
challenger_glm <- glm(Fail ~ Temperature, family = binomial, data = challenger)
summary(challenger_glm)
# fit the model
logistic_challenger <- glm(Fail ~ Temperature, family = binomial, data = challenger)
logistic_challenger_null <- glm(Fail ~ 1, family = binomial, data = challenger)
anova(logistic_challenger_null, logistic_challenger, test = "LRT")
summary(logistic_challenger)
# fit the model
logistic_challenger <- glm(Fail ~ Temperature, family = binomial, data = challenger)
logistic_challenger_null <- glm(Fail ~ 1, family = binomial, data = challenger)
anova(logistic_challenger_null, logistic_challenger, test = "LRT")
drop1(logistic_challenger, test = "LRT")
summary(logistic_challenger)
# fit the model
logistic_challenger <- glm(Fail ~ Temperature, family = binomial, data = challenger)
logistic_challenger_null <- glm(Fail ~ 1, family = binomial, data = challenger)
anova(logistic_challenger_null, logistic_challenger, test = "LRT")
drop1(logistic_challenger, test = "LRT")
summary(logistic_challenger)
e^(10 *-0.2322)
exp(10 *-0.2322)
exp(-10 *-0.2322)
View(challenger)
## Your code here
new_data = data.frame(temperature = 30)
predict(logistic_challenger, new_data, type = 'response')
## Your code here
new_data = data.frame(Temperature = 30)
predict(logistic_challenger, new_data, type = 'response')
?predict
?confint
## Your code here
confint(logistic_challenger, level = 0.95)
# create new data
new_data = data.frame(Temperature = 30)
# make prediction
predict(logistic_challenger, new_data, type = 'response', interval = 'confidence')
# assess the output using summary
# I used drop1 before, but that's the same as anove before
summary(logistic_challenger)
knitr::kable(head(iris))
summary(iris)
iris_vv <- subset(iris, Species != "setosa")
qplot(Sepal.Length, Sepal.Width, color = Species, shape = Species, data = iris_vv) +
scale_color_brewer(palette = "Accent")
## Your code here
logistic_iris <- glm(Species ~ Sepal.Width, data = iris_vv, family = binomial)
drop1(logistic_iris, test = 'LRT')
summary(logistic_iris)
View(iris_vv)
## Your code here
cutoff             <- 0.5
predicted_iris <- predict(logistic_iris, iris_vv, type = 'response')
predicted_iris <- ifelse(predicted_iris > cutoff, 1, 0)
mean(predicted_iris != iris_vv$Species)
mean(iris_vv$Species)
## Your code here
cutoff             <- 0.5
predicted_iris <- predict(logistic_iris, iris_vv, type = 'response')
predicted_iris <- ifelse(predicted_iris > cutoff, 1, 0)
mean(predicted_iris != iris_vv$Species)
mean(iris_vv$Species, na.rm = t)
View(iris_vv)
predict(logistic_iris, iris_vv, type = 'response')
sum(predict(logistic_iris, iris_vv, type = 'response'))
mean(predicted_iris != iris_vv$Species)
predicted_iris
summary(logistic_iris)
View(iris_vv)
## Your code here
cutoff             <- 0.5
predicted_iris <- predict(logistic_iris, iris_vv, type = 'response')
predicted_iris <- ifelse(predicted_iris > cutoff, 1, 0)
# convert species to 1 and 0
iris_vv$Species_binomial <- ifelse(iris_vv$Species == 'versicolor', 1, 0)
mean(predicted_iris != iris_vv$Species_binomial)
mean(iris_vv$Species_binomial, na.rm = T)
## Your code here
cutoff             <- 0.5
predicted_iris <- predict(logistic_iris, iris_vv, type = 'response')
predicted_iris <- ifelse(predicted_iris > cutoff, 1, 0)
# convert species to 1 and 0
iris_vv$Species_binomial <- ifelse(iris_vv$Species == 'versicolor', 0, 1)
mean(predicted_iris != iris_vv$Species_binomial)
mean(iris_vv$Species_binomial, na.rm = T)
## Your code here
cutoff             <- 0.5
predicted_iris <- predict(logistic_iris, iris_vv, type = 'response') # predicting the probability of a flower being virginica
predicted_iris <- ifelse(predicted_iris > cutoff, 1, 0)
# convert species to 1 and 0
iris_vv$Species_binomial <- ifelse(iris_vv$Species == 'versicolor', 0, 1)
mean(predicted_iris != iris_vv$Species_binomial)
mean(iris_vv$Species_binomial)
## Your code here
# fit model
logistic_iris2 <- glm(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data = iris_vv, family = binomial)
cutoff             <- 0.5
predicted_iris <- predict(logistic_iris2, iris_vv, type = 'response') # predicting the probability of a flower being virginica
predicted_iris <- ifelse(predicted_iris > cutoff, 1, 0)
# convert species to 1 and 0
iris_vv$Species_binomial <- ifelse(iris_vv$Species == 'versicolor', 0, 1)
mean(predicted_iris != iris_vv$Species_binomial)
mean(iris_vv$Species_binomial)
# output model slopes
summary(logistic_iris)
summary(logistic_iris2)
drop1(logisitc_iris, test = 'LRT')
drop1(logistic_iris, test = 'LRT')
drop1(logistic_iris2, test = 'LRT')
drop1(logistic_iris, test = 'LRT')
summary(logistic_iris)
drop1(logistic_iris, test = 'LRT')
# import necessary libraries
library(tidyverse)
library(ggfortify) # for autoplot
library(nycflights13)
# load the data
data("flights") # the primary dataset I will be using
data("airlines") # key for the airline carrier abbreviations and full names
data("airports") # contains information for each of the airports
data("planes") # contains information on all the planes flown
data("weather") # contains weather data on all the airports in NYC
# merge the data
flights <- flights %>% left_join(weather, by = join_by(year, month, day, origin, hour, time_hour)) %>% # joins all all the common columns
select(-dewp, -humid, -wind_dir, -wind_gust) %>%  # remove the columns I don't want
left_join(planes, by ='tailnum') %>%
select(-type, -manufacturer, -model, -speed) %>%
rename(year = year.x, plane_year = year.y) %>%
left_join(airlines, by = join_by(carrier)) %>%
rename(airline_name = name)
# retain only complete cases
flights <- flights[complete.cases(flights),]
airline_table <- data.frame(sort(table(flights$airline_name)))
knitr::kable(airline_table)
# ggplot(tab, aes(y = Var1, x = Freq)) + geom_bar(stat = 'identity')
ggplot(flights, aes(x = dep_delay)) + geom_histogram()
ggplot(flights, aes(x = dep_delay)) + geom_density()
ggplot(flights, aes(x = log(dep_delay))) + geom_histogram()
ggplot(flights, aes(x = log(dep_delay))) + geom_density()
# how many flights left early?
flights %>% filter(dep_delay < 0) %>% summarize(early_flights = n())
# visibility (19 unique)
ggplot(flights, aes(x = visib, y = dep_delay)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm') +
ggtitle('Relationship Between Departure Delay and Visibility') +
xlab('Visibility (miles)') + ylab('Departure Delay (min)')
# winds (32 unique)
ggplot(flights, aes(x = wind_speed, y = dep_delay)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm') +
ggtitle('Relationship Between Departure Delay and Wind Speed') +
xlab('Wind Speed (mph)') + ylab('Departure Delay (min)')
# precipitation
ggplot(flights, aes(x = precip, y = dep_delay)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm') +
ggtitle('Relationship Between Departure Delay and Precipitation') +
xlab('Precipitation (in)') + ylab('Departure Delay (min)')
# pressure
ggplot(flights, aes(x = pressure, y = dep_delay)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm') +
ggtitle('Relationship Between Departure Delay and Pressure') +
xlab('Pressure (millibars)') + ylab('Departure Delay (min)')
ggplot(flights, aes(x = carrier, y = dep_delay)) + geom_boxplot() + ggtitle('Flights Delays By Airline')
ggplot(flights, aes(x = carrier, y = log(dep_delay))) + geom_boxplot() + ggtitle('Flights Delays By Airline')
ggplot(flights, aes(x = carrier, y = dep_delay)) + geom_bar(stat = 'summary') + geom_errorbar(stat = 'summary') + ggtitle('Flights Delays By Airline')
# 46 unique manufacture years
ggplot(flights, aes(x = plane_year, y = dep_delay)) + geom_point() + geom_smooth(method = 'lm')
# fit the model
flights_lm <- lm(dep_delay ~ visib + wind_speed + precip + pressure + airline_name + plane_year, data = flights)
# output summary
summary(flights_lm)
autoplot(flights_lm)
View(flights)
library(tidyverse)
library(ggfortify)
library(car)
library(pheatmap)
colorize <- function(x, color = 2) {
cols <- palette.colors()
color <- cols[color + 1]
if (knitr::is_latex_output()) {
sprintf("\\textcolor{%s}{%s}", color, x)
} else if (knitr::is_html_output()) {
sprintf("<span style='color: %s;'>%s</span>", color,
x)
} else x
}
boston <- MASS::Boston
knitr::kable(head(boston))
boston_sub <- select(boston, -zn, -chas)
## Your code here
boston_cor <- cor(boston_sub, use = 'pairwise.complete')
print(boston_cor)
library(pheatmap)
pheatmap(boston_cor,
treeheight_col = 0,
treeheight_row = 0,
display_numbers = TRUE,
breaks = seq(-1, 1, length = 101))
# fit model
boston_lm <- lm(medv ~ nox + lstat + age + dis + rad + black + tax + ptratio, data = boston_sub)
# output summary
summary(boston_lm)
library(car)
# compute variance inflation factors
boston_vifs <- vif(boston_lm)
print(boston_vifs)
# fit the new model
boston_lm2 <- lm(medv ~ nox + lstat + age + dis + black + ptratio, data = boston_sub)
summary(boston_lm2)
## Load Data
sat_file <- str_c(
"https://raw.githubusercontent.com/theodds/SDS-348/master/satgpa.csv"
)
sat_gpa <- read.csv(sat_file)
sat_gpa <- sat_gpa[,-4]
knitr::kable(head(sat_gpa))
# cor matrix
sat_gpa_cor <- cor(sat_gpa, use = 'pairwise.complete')
pheatmap(sat_gpa_cor,
treeheight_col = 0,
treeheight_row = 0,
display_numbers = TRUE,
breaks = seq(-1, 1, length = 101))
# fit the model
sat_gpa_lm <- lm(fy_gpa ~ ., data = sat_gpa)
summary(sat_gpa_lm)
# plot VIFs
barplot(vif(sat_gpa_lm), xlab = "Variable", col = 'steelblue', ylab = "VIF")
# fit the model
sex_lm <- lm(sex ~ hs_gpa + sat_m + sat_v, data = sat_gpa)
summary(sex_lm)
sex_vif <- 1/(1 - .13)
print(sex_vif)
